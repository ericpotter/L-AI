{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\AI\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**人工智能（AI）** 是一種模擬人類智能的技術，讓電腦系統能夠執行通常需要人類智慧才能完成的任務。\n",
       "\n",
       "**AI 的主要特徵包括：**\n",
       "\n",
       "* **學習和適應：** AI 系統能夠從數據中學習，並根據新的信息調整其行為。\n",
       "* **問題解決：** AI 系統能夠解決複雜的問題，並找到最佳的解決方案。\n",
       "* **決策：** AI 系統能夠做出明智的決策，並根據數據和邏輯進行判斷。\n",
       "* **自然語言處理：** AI 系統可以理解和生成人類語言，例如文本和語音。\n",
       "* **視覺識別：** AI 系統可以識別和分析圖像和視頻。\n",
       "\n",
       "**AI 的應用領域：**\n",
       "\n",
       "* **自動駕駛汽車**\n",
       "* **醫療診斷**\n",
       "* **金融交易**\n",
       "* **客戶服務**\n",
       "* **遊戲開發**\n",
       "* **機器人**\n",
       "* **語音助理**\n",
       "\n",
       "**AI 的類型：**\n",
       "\n",
       "* **機器學習：** 讓電腦系統從數據中學習，而無需明確編程。\n",
       "* **深度學習：** 是一種機器學習的子類別，使用人工神經網絡來處理大型數據集。\n",
       "* **自然語言處理 (NLP)：** 讓電腦系統理解和生成人類語言。\n",
       "* **電腦視覺：** 讓電腦系統識別和分析圖像和視頻。\n",
       "\n",
       "**AI 的未來發展：**\n",
       "\n",
       "* **更強大的計算能力**\n",
       "* **更大量的數據**\n",
       "* **更先進的算法**\n",
       "* **更廣泛的應用**\n",
       "\n",
       "總之，AI 是一種強大的技術，可以改變我們的生活和工作方式。它正在迅速發展，並將繼續在未來發揮越來越重要的作用。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
    "input_msg = input(\"請輸入問題\")\n",
    "result = model.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"請使用繁體中文回答。\"),\n",
    "        HumanMessage(content=input_msg),\n",
    "    ]\n",
    ")\n",
    "display(Markdown(result.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from functools import partial\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List, Union\n",
    "from operator import itemgetter\n",
    "\n",
    "def RPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(f\"{preface}{x}\")\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def PPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(preface, x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "## Zero-shot classification prompt and chain w/ explicit few-shot prompting\n",
    "sys_msg = (\n",
    "    \"Choose the most likely topic classification given the sentence as context.\"\n",
    "    \" Only one word, no explanation.\\n[Options : {options}]\"\n",
    ")\n",
    "\n",
    "zsc_prompt = ChatPromptTemplate.from_template(\n",
    "    f\"{sys_msg}\\n\\n\"\n",
    "    \"[[The sea is awesome]][/INST]boat</s><s>[INST]\"\n",
    "    \"[[{input}]]\"\n",
    ")\n",
    "\n",
    "## Define your simple instruct_model\n",
    "instruct_chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
    "instruct_llm = instruct_chat | StrOutputParser()\n",
    "one_word_llm = instruct_chat.bind(stop=[\" \", \"\\n\"]) | StrOutputParser() # stop the output\n",
    "\n",
    "zsc_chain = zsc_prompt | one_word_llm\n",
    "\n",
    "## Function that just prints out the first word of the output. With early stopping bind\n",
    "def zsc_call(input, options=[\"car\", \"boat\", \"airplane\", \"bike\"]):\n",
    "    return zsc_chain.invoke({\"input\" : input, \"options\" : options}).split()[0]\n",
    "\n",
    "print(zsc_call(\"Should I take the next exit, or keep going to the next one?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  {'topic': 'boat'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The old, weathered boat, a seasoned traveler of the seas, whispered tales of forgotten islands and whispered secrets to the moonlit waves. \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Make a new sentence about the the following topic: {topic}. Be creative!\"\n",
    ")\n",
    "\n",
    "gen_chain = gen_prompt | instruct_llm\n",
    "\n",
    "input_msg = \"I get seasick, so I think I'll pass on the trip\"\n",
    "options = [\"car\", \"boat\", \"airplane\", \"bike\"]\n",
    "\n",
    "chain = (\n",
    "    ## -> {\"input\", \"options\"}\n",
    "    {'topic' : zsc_chain}\n",
    "    | PPrint()\n",
    "    ## -> {**, \"topic\"}\n",
    "    | gen_chain\n",
    "    ## -> string\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\" : input_msg, \"options\" : options})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
