{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\26855\\anaconda3\\envs\\AI\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\26855\\Desktop\\Github\\AI\\langchain\\langchain.py:49: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  .replace(\"\\]\", \"]\")\n",
      "c:\\Users\\26855\\Desktop\\Github\\AI\\langchain\\langchain.py:50: SyntaxWarning: invalid escape sequence '\\['\n",
      "  .replace(\"\\[\", \"[\")\n",
      "c:\\Users\\26855\\anaconda3\\envs\\AI\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**人工智慧 (AI)** 是一種模擬人類智慧的電腦科學領域。它涉及開發能夠執行通常需要人類智慧才能完成的任務的系統。\n",
       "\n",
       "**AI 的主要特徵包括：**\n",
       "\n",
       "* **學習：** AI 系統可以從數據中學習，並隨著時間推移改善其性能。\n",
       "* **推理：** AI 系統可以進行邏輯推理，得出結論並解決問題。\n",
       "* **決策：** AI 系統可以根據數據和推理做出決策。\n",
       "* **自然語言處理：** AI 系統可以理解和生成人類語言。\n",
       "* **電腦視覺：** AI 系統可以「看到」和理解圖像。\n",
       "\n",
       "**AI 的應用領域十分廣泛，包括：**\n",
       "\n",
       "* **自動駕駛汽車**\n",
       "* **虛擬助理**\n",
       "* **醫療診斷**\n",
       "* **金融交易**\n",
       "* **客戶服務**\n",
       "* **遊戲**\n",
       "\n",
       "**AI 的類型：**\n",
       "\n",
       "* **狹義人工智慧 (Narrow AI)：** 針對特定任務設計的 AI 系統，例如面部識別或語音轉文字。\n",
       "* **通用人工智慧 (General AI)：** 具有與人類相同的認知能力，能夠執行任何智力任務的 AI 系統。\n",
       "* **超級人工智慧 (Super AI)：** 超越人類智慧的 AI 系統，能夠解決人類無法解決的問題。\n",
       "\n",
       "**AI 的未來：**\n",
       "\n",
       "AI 的發展正在迅速進行，預計將在未來繼續對社會產生深遠的影響。AI 將繼續自動化任務、改進決策過程，並為人類創造新的機會。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
    "input_msg = input(\"請輸入問題\")\n",
    "result = model.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"請使用繁體中文回答。\"),\n",
    "        HumanMessage(content=input_msg),\n",
    "    ]\n",
    ")\n",
    "display(Markdown(result.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from functools import partial\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List, Union\n",
    "from operator import itemgetter\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)\n",
    "\n",
    "# Useful Tools\n",
    "def RPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(f\"{preface}{x}\")\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def PPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        pprint(preface, x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "## Zero-shot classification prompt and chain w/ explicit few-shot prompting\n",
    "sys_msg = (\n",
    "    \"Choose the most likely topic classification given the sentence as context.\"\n",
    "    \" Only one word, no explanation.\\n[Options : {options}]\"\n",
    ")\n",
    "\n",
    "zsc_prompt = ChatPromptTemplate.from_template(\n",
    "    f\"{sys_msg}\\n\\n\"\n",
    "    \"[[The sea is awesome]][/INST]boat</s><s>[INST]\"\n",
    "    \"[[{input}]]\"\n",
    ")\n",
    "\n",
    "## Define your simple instruct_model\n",
    "instruct_chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
    "instruct_llm = instruct_chat | StrOutputParser()\n",
    "one_word_llm = instruct_chat.bind(stop=[\" \", \"\\n\"]) | StrOutputParser() # stop the output\n",
    "\n",
    "zsc_chain = zsc_prompt | one_word_llm\n",
    "\n",
    "## Function that just prints out the first word of the output. With early stopping bind\n",
    "def zsc_call(input, options=[\"car\", \"boat\", \"airplane\", \"bike\"]):\n",
    "    return zsc_chain.invoke({\"input\" : input, \"options\" : options}).split()[0]\n",
    "\n",
    "print(zsc_call(\"Should I take the next exit, or keep going to the next one?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  {'topic': 'boat'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The old sailboat, its weathered hull whispering tales of distant shores, dreamt of escaping its moorings and dancing with the wind once more. \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Make a new sentence about the the following topic: {topic}. Be creative!\"\n",
    ")\n",
    "\n",
    "gen_chain = gen_prompt | instruct_llm\n",
    "\n",
    "input_msg = \"I get seasick, so I think I'll pass on the trip\"\n",
    "options = [\"car\", \"boat\", \"airplane\", \"bike\"]\n",
    "\n",
    "chain = (\n",
    "    ## -> {\"input\", \"options\"}\n",
    "    {'topic' : zsc_chain}\n",
    "    | PPrint()\n",
    "    ## -> {**, \"topic\"}\n",
    "    | gen_chain\n",
    "    ## -> string\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\" : input_msg, \"options\" : options})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\26855\\anaconda3\\envs\\AI\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\26855\\Desktop\\Github\\AI\\langchain\\langchain.py:49: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  .replace(\"\\]\", \"]\")\n",
      "c:\\Users\\26855\\Desktop\\Github\\AI\\langchain\\langchain.py:50: SyntaxWarning: invalid escape sequence '\\['\n",
      "  .replace(\"\\[\", \"[\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.schema'; 'langchain' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableBranch, RunnablePassthrough\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpassthrough\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableAssign\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n",
      "File \u001b[1;32mc:\\Users\\26855\\Desktop\\Github\\AI\\langchain\\langchain.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableLambda\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableBranch, RunnablePassthrough\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpassthrough\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableAssign\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticOutputParser\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.schema'; 'langchain' is not a package"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableBranch, RunnablePassthrough\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from functools import partial\n",
    "\n",
    "big_chain = (\n",
    "    PPrint()\n",
    "    ## Manual mapping. Can be useful sometimes and inside branch chains\n",
    "    | {'input' : lambda d: d.get('input'), 'topic' : zsc_chain}\n",
    "    | PPrint()\n",
    "    ## RunnableAssign passing. Better for running state chains by default\n",
    "    | RunnableAssign({'generation' : gen_chain})\n",
    "    | PPrint()\n",
    "    ## Using the input and generation together\n",
    "    | RunnableAssign({'combination' : (\n",
    "        ChatPromptTemplate.from_template(\n",
    "            \"Consider the following passages:\"\n",
    "            \"\\nP1: {input}\"\n",
    "            \"\\nP2: {generation}\"\n",
    "            \"\\n\\nCombine the ideas from both sentences into one simple one.\"\n",
    "        )\n",
    "        | instruct_llm\n",
    "    )})\n",
    ")\n",
    "\n",
    "output = big_chain.invoke({\n",
    "    \"input\" : \"I get seasick, so I think I'll pass on the trip\",\n",
    "    \"options\" : [\"car\", \"boat\", \"airplane\", \"bike\", \"unknown\"]\n",
    "})\n",
    "pprint(\"Final Output: \", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
