{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\AI\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI，全稱**人工智慧**，是一種模擬人類智慧的技術。它涵蓋了許多不同的領域，例如：\n",
       "\n",
       "* **機器學習 (Machine Learning)**：讓電腦從數據中學習，並自動改進其表現，例如：辨識圖片、預測天氣。\n",
       "* **深度學習 (Deep Learning)**：一種更複雜的機器學習，使用神經網路來處理大量數據，例如：自動翻譯、語音辨識。\n",
       "* **自然語言處理 (Natural Language Processing)**：讓電腦理解和處理人類語言，例如：聊天機器人、自動摘要。\n",
       "* **電腦視覺 (Computer Vision)**：讓電腦像人類一樣「看」和「理解」影像，例如：自動駕駛、影像辨識。\n",
       "* **機器人學 (Robotics)**：設計和製造機器人，讓它們能夠執行各種任務，例如：自動化生產、醫療輔助。\n",
       "\n",
       "**簡單來說，AI就是讓電腦像人類一樣思考和行動的技術。**它可以幫助我們解決各種問題，例如：提高生產效率、改善醫療保健、促進科學研究等等。\n",
       "\n",
       "**AI的發展還在不斷進步，未來將會在更多領域發揮作用。**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
    "input_msg = input(\"請輸入問題\")\n",
    "result = model.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"請使用繁體中文回答。\"),\n",
    "        HumanMessage(content=input_msg),\n",
    "    ]\n",
    ")\n",
    "display(Markdown(result.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from functools import partial\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List, Union\n",
    "from operator import itemgetter\n",
    "\n",
    "def RPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(f\"{preface}{x}\")\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def PPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(preface, x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "## Zero-shot classification prompt and chain w/ explicit few-shot prompting\n",
    "sys_msg = (\n",
    "    \"Choose the most likely topic classification given the sentence as context.\"\n",
    "    \" Only one word, no explanation.\\n[Options : {options}]\"\n",
    ")\n",
    "\n",
    "zsc_prompt = ChatPromptTemplate.from_template(\n",
    "    f\"{sys_msg}\\n\\n\"\n",
    "    \"[[The sea is awesome]][/INST]boat</s><s>[INST]\"\n",
    "    \"[[{input}]]\"\n",
    ")\n",
    "\n",
    "## Define your simple instruct_model\n",
    "instruct_chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
    "instruct_llm = instruct_chat | StrOutputParser()\n",
    "one_word_llm = instruct_chat.bind(stop=[\" \", \"\\n\"]) | StrOutputParser() # stop the output\n",
    "\n",
    "zsc_chain = zsc_prompt | one_word_llm\n",
    "\n",
    "## Function that just prints out the first word of the output. With early stopping bind\n",
    "def zsc_call(input, options=[\"car\", \"boat\", \"airplane\", \"bike\"]):\n",
    "    return zsc_chain.invoke({\"input\" : input, \"options\" : options}).split()[0]\n",
    "\n",
    "print(zsc_call(\"Should I take the next exit, or keep going to the next one?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  {'topic': 'boat'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The old, weathered boat, its hull a mosaic of barnacles and memories, whispered tales of distant shores and forgotten dreams as it bobbed gently on the waves. \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Make a new sentence about the the following topic: {topic}. Be creative!\"\n",
    ")\n",
    "\n",
    "gen_chain = gen_prompt | instruct_llm\n",
    "\n",
    "input_msg = \"I get seasick, so I think I'll pass on the trip\"\n",
    "options = [\"car\", \"boat\", \"airplane\", \"bike\"]\n",
    "\n",
    "chain = (\n",
    "    ## -> {\"input\", \"options\"}\n",
    "    {'topic' : zsc_chain}\n",
    "    | PPrint()\n",
    "    ## -> {**, \"topic\"}\n",
    "    | gen_chain\n",
    "    ## -> string\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\" : input_msg, \"options\" : options})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
